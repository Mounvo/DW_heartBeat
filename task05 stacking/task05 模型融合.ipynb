{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southern-reproduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred1 MAE: 0.1750000000000001\n",
      "Pred2 MAE: 0.07499999999999993\n",
      "Pred3 MAE: 0.10000000000000009\n",
      "Weighted_pre MAE: 0.05750000000000027\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "# 生成一些简单的样本数据，test_prei 代表第i个模型的预测值\n",
    "test_pre1 = [1.2, 3.2, 2.1, 6.2]\n",
    "test_pre2 = [0.9, 3.1, 2.0, 5.9]\n",
    "test_pre3 = [1.1, 2.9, 2.2, 6.0]\n",
    "\n",
    "# y_test_true 代表第模型的真实值\n",
    "y_test_true = [1, 3, 2, 6] \n",
    "\n",
    "# 定义结果的加权平均函数\n",
    "def Weighted_method(test_pre1,test_pre2,test_pre3,w=[1/3,1/3,1/3]):\n",
    "    Weighted_result = w[0]*pd.Series(test_pre1)+w[1]*pd.Series(test_pre2)+w[2]*pd.Series(test_pre3)\n",
    "    return Weighted_result\n",
    "\n",
    "# 各模型的预测结果计算MAE\n",
    "print('Pred1 MAE:',metrics.mean_absolute_error(y_test_true, test_pre1))\n",
    "print('Pred2 MAE:',metrics.mean_absolute_error(y_test_true, test_pre2))\n",
    "print('Pred3 MAE:',metrics.mean_absolute_error(y_test_true, test_pre3))\n",
    "\n",
    "# 根据加权计算MAE\n",
    "w = [0.3,0.4,0.3] # 定义比重权值\n",
    "Weighted_pre = Weighted_method(test_pre1,test_pre2,test_pre3,w)\n",
    "print('Weighted_pre MAE:',metrics.mean_absolute_error(y_test_true, Weighted_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "disciplinary-petite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_pre MAE: 0.06666666666666693\n"
     ]
    }
   ],
   "source": [
    "# mean平均\n",
    "def Mean_method(test_pre1,test_pre2,test_pre3):\n",
    "    Mean_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).mean(axis=1)\n",
    "    return Mean_result\n",
    "\n",
    "Mean_pre = Mean_method(test_pre1,test_pre2,test_pre3)\n",
    "print('Mean_pre MAE:',metrics.mean_absolute_error(y_test_true, Mean_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "individual-victor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median_pre MAE: 0.07500000000000007\n"
     ]
    }
   ],
   "source": [
    "# median平均\n",
    "def Median_method(test_pre1,test_pre2,test_pre3):\n",
    "    Median_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).median(axis=1)\n",
    "    return Median_result\n",
    "\n",
    "Median_pre = Median_method(test_pre1,test_pre2,test_pre3)\n",
    "print('Median_pre MAE:',metrics.mean_absolute_error(y_test_true, Median_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expanded-talent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking_pre MAE: 0.04213483146067476\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def Stacking_method(train_reg1,train_reg2,train_reg3,y_train_true,test_pre1,test_pre2,test_pre3,model_L2= linear_model.LinearRegression()):\n",
    "    model_L2.fit(pd.concat([pd.Series(train_reg1),pd.Series(train_reg2),pd.Series(train_reg3)],axis=1).values,y_train_true)\n",
    "    Stacking_result = model_L2.predict(pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).values)\n",
    "    return Stacking_result\n",
    "\n",
    "# 生成一些简单的样本数据，test_prei 代表第i个模型的预测值\n",
    "train_reg1 = [3.2, 8.2, 9.1, 5.2]\n",
    "train_reg2 = [2.9, 8.1, 9.0, 4.9]\n",
    "train_reg3 = [3.1, 7.9, 9.2, 5.0]\n",
    "# y_test_true 代表第模型的真实值\n",
    "y_train_true = [3, 8, 9, 5] \n",
    "\n",
    "test_pre1 = [1.2, 3.2, 2.1, 6.2]\n",
    "test_pre2 = [0.9, 3.1, 2.0, 5.9]\n",
    "test_pre3 = [1.1, 2.9, 2.2, 6.0]\n",
    "\n",
    "# y_test_true 代表第模型的真实值\n",
    "y_test_true = [1, 3, 2, 6] \n",
    "\n",
    "model_L2= linear_model.LinearRegression()\n",
    "Stacking_pre = Stacking_method(train_reg1,train_reg2,train_reg3,y_train_true,\n",
    "                               test_pre1,test_pre2,test_pre3,model_L2)\n",
    "print('Stacking_pre MAE:',metrics.mean_absolute_error(y_test_true, Stacking_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spare-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bridal-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.05) [LGB]\n",
      "Accuracy: 0.33 (+/- 0.00) [Random Forest]\n",
      "Accuracy: 0.92 (+/- 0.03) [SVM]\n",
      "Accuracy: 0.93 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
    "\n",
    "clf1 = lgb.LGBMClassifier(learning_rate=0.1, n_estimators=150, max_depth=3, min_child_weight=2, subsample=0.7,\n",
    "                     colsample_bytree=0.6, objective='binary:logistic')\n",
    "clf2 = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=10,\n",
    "                              min_samples_leaf=63,oob_score=True)\n",
    "clf3 = SVC(C=0.1)\n",
    "\n",
    "# 硬投票\n",
    "eclf = VotingClassifier(estimators=[('lgb', clf1), ('rf', clf2), ('svc', clf3)], voting='hard')\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['LGB', 'Random Forest', 'SVM', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, x, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "worth-suicide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val auc Score: 1.000000\n",
      "val auc Score: 0.500000\n",
      "val auc Score: 0.500000\n",
      "val auc Score: 0.500000\n",
      "val auc Score: 0.500000\n",
      "Val auc Score of Stacking: 1.000000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "5-Fold Stacking\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier,GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "#创建训练的数据集\n",
    "data_0 = iris.data\n",
    "data = data_0[:100,:]\n",
    "\n",
    "target_0 = iris.target\n",
    "target = target_0[:100]\n",
    "\n",
    "#模型融合中使用到的各个单模型\n",
    "clfs = [LogisticRegression(solver='lbfgs'),\n",
    "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
    "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]\n",
    " \n",
    "#切分一部分数据作为测试集\n",
    "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)\n",
    "\n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_predict.shape[0], len(clfs)))\n",
    "\n",
    "#5折stacking\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits)\n",
    "skf = skf.split(X, y)\n",
    "\n",
    "for j, clf in enumerate(clfs):\n",
    "    #依次训练各个单模型\n",
    "    dataset_blend_test_j = np.zeros((X_predict.shape[0], 5))\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        #5-Fold交叉训练，使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。\n",
    "        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:, 1]\n",
    "        dataset_blend_train[test, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 1]\n",
    "    #对于测试集，直接用这k个模型的预测值均值作为新的特征。\n",
    "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_blend_test[:, j]))\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(dataset_blend_train, y)\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "print(\"Val auc Score of Stacking: %f\" % (roc_auc_score(y_predict, y_submission)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sunrise-device",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val auc Score: 1.000000\n",
      "val auc Score: 1.000000\n",
      "val auc Score: 1.000000\n",
      "val auc Score: 1.000000\n",
      "val auc Score: 1.000000\n",
      "Val auc Score of Blending: 1.000000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Blending\n",
    "'''\n",
    " \n",
    "#创建训练的数据集\n",
    "#创建训练的数据集\n",
    "data_0 = iris.data\n",
    "data = data_0[:100,:]\n",
    "\n",
    "target_0 = iris.target\n",
    "target = target_0[:100]\n",
    " \n",
    "#模型融合中使用到的各个单模型\n",
    "clfs = [LogisticRegression(solver='lbfgs'),\n",
    "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
    "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "        #ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
    "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]\n",
    "\n",
    "#切分一部分数据作为测试集\n",
    "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)\n",
    "\n",
    "#切分训练数据集为d1,d2两部分\n",
    "X_d1, X_d2, y_d1, y_d2 = train_test_split(X, y, test_size=0.5, random_state=2020)\n",
    "dataset_d1 = np.zeros((X_d2.shape[0], len(clfs)))\n",
    "dataset_d2 = np.zeros((X_predict.shape[0], len(clfs)))\n",
    " \n",
    "for j, clf in enumerate(clfs):\n",
    "    #依次训练各个单模型\n",
    "    clf.fit(X_d1, y_d1)\n",
    "    y_submission = clf.predict_proba(X_d2)[:, 1]\n",
    "    dataset_d1[:, j] = y_submission\n",
    "    #对于测试集，直接用这k个模型的预测值作为新的特征。\n",
    "    dataset_d2[:, j] = clf.predict_proba(X_predict)[:, 1]\n",
    "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_d2[:, j]))\n",
    "\n",
    "#融合使用的模型\n",
    "clf = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)\n",
    "clf.fit(dataset_d1, y_d2)\n",
    "y_submission = clf.predict_proba(dataset_d2)[:, 1]\n",
    "print(\"Val auc Score of Blending: %f\" % (roc_auc_score(y_predict, y_submission)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-briefs",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
